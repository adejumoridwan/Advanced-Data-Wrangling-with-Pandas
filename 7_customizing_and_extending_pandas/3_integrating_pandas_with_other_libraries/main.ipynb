{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ntegrating Pandas with Other Data Science Libraries (NumPy, Scikit-learn)\n",
    "\n",
    "## Introduction to Numpy and Scikit-learn\n",
    "NumPy: A fundamental library for numerical computing in Python.\n",
    "Scikit-learn: A robust library for machine learning in Python.\n",
    "\n",
    "### Creating a Dataset with Python Faker\n",
    "First, install the required libraries if you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name  age  salary                city  purchase_amount\n",
      "0                John Allen   36   62325        Nicholsmouth            49855\n",
      "1                John Weber   36   74276  North Kimberlyport            48734\n",
      "2  Mrs. Barbara Mcintyre MD   43   81505          New Nicole            44109\n",
      "3       Dr. Colleen Shannon   44   92182     North Cassandra            25202\n",
      "4           Mr. Joshua Diaz   50  110606         West Nicole            22587\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Create a dataset\n",
    "data = {\n",
    "    'name': [fake.name() for _ in range(100)],\n",
    "    'age': [fake.random_int(min=18, max=80) for _ in range(100)],\n",
    "    'salary': [fake.random_int(min=30000, max=120000) for _ in range(100)],\n",
    "    'city': [fake.city() for _ in range(100)],\n",
    "    'purchase_amount': [fake.random_number(digits=5) for _ in range(100)]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NumPy with Pandas\n",
    "\n",
    "NumPy arrays can be used for efficient numerical operations. Hereâ€™s how you can integrate NumPy with Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36 36 43 44 50]\n",
      "Mean age: 48.37\n",
      "                       name  age  salary                city  purchase_amount  \\\n",
      "0                John Allen   36   62325        Nicholsmouth            49855   \n",
      "1                John Weber   36   74276  North Kimberlyport            48734   \n",
      "2  Mrs. Barbara Mcintyre MD   43   81505          New Nicole            44109   \n",
      "3       Dr. Colleen Shannon   44   92182     North Cassandra            25202   \n",
      "4           Mr. Joshua Diaz   50  110606         West Nicole            22587   \n",
      "\n",
      "   age_squared  \n",
      "0         1296  \n",
      "1         1296  \n",
      "2         1849  \n",
      "3         1936  \n",
      "4         2500  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert a Pandas column to a NumPy array\n",
    "ages = df['age'].values\n",
    "print(ages[:5])\n",
    "\n",
    "# Perform a NumPy operation\n",
    "mean_age = np.mean(ages)\n",
    "print(f\"Mean age: {mean_age}\")\n",
    "\n",
    "# Add a new column with NumPy operations\n",
    "df['age_squared'] = np.square(df['age'])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing with Scikit-learn\n",
    "Scikit-learn provides tools for preprocessing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t-0.7198273493389845\n",
      "  (0, 1)\t-0.3844253575991263\n",
      "  (0, 2)\t-0.05535646154969576\n",
      "  (0, 53)\t1.0\n",
      "  (1, 0)\t-0.7198273493389845\n",
      "  (1, 1)\t0.061782480076450576\n",
      "  (1, 2)\t-0.09636531259199622\n",
      "  (1, 61)\t1.0\n",
      "  (2, 0)\t-0.31248770137027854\n",
      "  (2, 1)\t0.33168763098907256\n",
      "  (2, 2)\t-0.2655588327263759\n",
      "  (2, 49)\t1.0\n",
      "  (3, 0)\t-0.2542963230890348\n",
      "  (3, 1)\t0.7303288394956523\n",
      "  (3, 2)\t-0.9572219430357202\n",
      "  (3, 57)\t1.0\n",
      "  (4, 0)\t0.09485194659842738\n",
      "  (4, 1)\t1.418215476708842\n",
      "  (4, 2)\t-1.0528848738792667\n",
      "  (4, 96)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the columns\n",
    "numeric_features = ['age', 'salary', 'purchase_amount']\n",
    "categorical_features = ['city']\n",
    "\n",
    "# Create transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the dataset\n",
    "df_preprocessed = preprocessor.fit_transform(df)\n",
    "print(df_preprocessed[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame head:\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "Mean Squared Error: 0.03711379440797688\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to DataFrame for better readability (optional)\n",
    "df = pd.DataFrame(data=X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Print DataFrame head to inspect the data\n",
    "print(\"DataFrame head:\\n\", df.head())\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a preprocessor (standard scaler in this case)\n",
    "preprocessor = StandardScaler()\n",
    "\n",
    "# Create a pipeline that includes preprocessing and model training\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
